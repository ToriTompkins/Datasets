{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started with PyTorch: A Deep Learning Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import pandas as pd\n",
    "import torch.utils.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the dataset and set hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataset = pd.read_csv(\"..\\\\train.csv\", header=None)\n",
    "testDataset = pd.read_csv(\"..\\\\test.csv\", header=None)\n",
    "\n",
    "inputSize = len(trainDataset.columns) -1\n",
    "hidden1Size = 128\n",
    "hidden2Size = 128\n",
    "numClasses = 2\n",
    "numEpoch = 100\n",
    "batchSize = 100\n",
    "learningRate = 0.001\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainLoader = torch.utils.data.DataLoader(dataset=torch.tensor(trainDataset.values), batch_size=batchSize, shuffle=True)\n",
    "testLoader = torch.utils.data.DataLoader(dataset=torch.tensor(testDataset.values), batch_size=batchSize, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepNeuralNetwork(nn.Module):\n",
    "    def __init__(self, inputSize, hidden1Size, hidden2Size, numClasses):\n",
    "        super(DeepNeuralNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(inputSize, hidden1Size)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden1Size, hidden2Size)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(hidden1Size, numClasses)\n",
    "        self.logsm1 = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.fc3(out)\n",
    "        out = self.logsm1(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn = DeepNeuralNetwork(inputSize, hidden1Size, hidden2Size, numClasses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set loss and optimisers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossFN = nn.NLLLoss()\n",
    "optimizer = torch.optim.Adam(dnn.parameters(), lr=learningRate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.0535\n",
      "Epoch [2/100], Loss: 0.2517\n",
      "Epoch [3/100], Loss: 0.0174\n",
      "Epoch [4/100], Loss: 0.2212\n",
      "Epoch [5/100], Loss: 0.0989\n",
      "Epoch [6/100], Loss: 0.0574\n",
      "Epoch [7/100], Loss: 0.1535\n",
      "Epoch [8/100], Loss: 0.0232\n",
      "Epoch [9/100], Loss: 0.1386\n",
      "Epoch [10/100], Loss: 0.0182\n",
      "Epoch [11/100], Loss: 0.0284\n",
      "Epoch [12/100], Loss: 0.0427\n",
      "Epoch [13/100], Loss: 0.0073\n",
      "Epoch [14/100], Loss: 0.0109\n",
      "Epoch [15/100], Loss: 0.0063\n",
      "Epoch [16/100], Loss: 0.1515\n",
      "Epoch [17/100], Loss: 0.0416\n",
      "Epoch [18/100], Loss: 0.0277\n",
      "Epoch [19/100], Loss: 0.0263\n",
      "Epoch [20/100], Loss: 0.0261\n",
      "Epoch [21/100], Loss: 0.0019\n",
      "Epoch [22/100], Loss: 0.0225\n",
      "Epoch [23/100], Loss: 0.0148\n",
      "Epoch [24/100], Loss: 0.0241\n",
      "Epoch [25/100], Loss: 0.1202\n",
      "Epoch [26/100], Loss: 0.0170\n",
      "Epoch [27/100], Loss: 0.0217\n",
      "Epoch [28/100], Loss: 0.0468\n",
      "Epoch [29/100], Loss: 0.0193\n",
      "Epoch [30/100], Loss: 0.1336\n",
      "Epoch [31/100], Loss: 0.0429\n",
      "Epoch [32/100], Loss: 0.0159\n",
      "Epoch [33/100], Loss: 0.0472\n",
      "Epoch [34/100], Loss: 0.0128\n",
      "Epoch [35/100], Loss: 0.0013\n",
      "Epoch [36/100], Loss: 0.0283\n",
      "Epoch [37/100], Loss: 0.0041\n",
      "Epoch [38/100], Loss: 0.0060\n",
      "Epoch [39/100], Loss: 0.0008\n",
      "Epoch [40/100], Loss: 0.0021\n",
      "Epoch [41/100], Loss: 0.0125\n",
      "Epoch [42/100], Loss: 0.0489\n",
      "Epoch [43/100], Loss: 0.0036\n",
      "Epoch [44/100], Loss: 0.1279\n",
      "Epoch [45/100], Loss: 0.0032\n",
      "Epoch [46/100], Loss: 0.0028\n",
      "Epoch [47/100], Loss: 0.0011\n",
      "Epoch [48/100], Loss: 0.0012\n",
      "Epoch [49/100], Loss: 0.0007\n",
      "Epoch [50/100], Loss: 0.0616\n",
      "Epoch [51/100], Loss: 0.0726\n",
      "Epoch [52/100], Loss: 0.0004\n",
      "Epoch [53/100], Loss: 0.0012\n",
      "Epoch [54/100], Loss: 0.0071\n",
      "Epoch [55/100], Loss: 0.0814\n",
      "Epoch [56/100], Loss: 0.0141\n",
      "Epoch [57/100], Loss: 0.0019\n",
      "Epoch [58/100], Loss: 0.0302\n",
      "Epoch [59/100], Loss: 0.0010\n",
      "Epoch [60/100], Loss: 0.0389\n",
      "Epoch [61/100], Loss: 0.1203\n",
      "Epoch [62/100], Loss: 0.0014\n",
      "Epoch [63/100], Loss: 0.0275\n",
      "Epoch [64/100], Loss: 0.0017\n",
      "Epoch [65/100], Loss: 0.0010\n",
      "Epoch [66/100], Loss: 0.0008\n",
      "Epoch [67/100], Loss: 0.0077\n",
      "Epoch [68/100], Loss: 0.0046\n",
      "Epoch [69/100], Loss: 0.0023\n",
      "Epoch [70/100], Loss: 0.0014\n",
      "Epoch [71/100], Loss: 0.1180\n",
      "Epoch [72/100], Loss: 0.0483\n",
      "Epoch [73/100], Loss: 0.0021\n",
      "Epoch [74/100], Loss: 0.0002\n",
      "Epoch [75/100], Loss: 0.0055\n",
      "Epoch [76/100], Loss: 0.0329\n",
      "Epoch [77/100], Loss: 0.1080\n",
      "Epoch [78/100], Loss: 0.0070\n",
      "Epoch [79/100], Loss: 0.0040\n",
      "Epoch [80/100], Loss: 0.0003\n",
      "Epoch [81/100], Loss: 0.0253\n",
      "Epoch [82/100], Loss: 0.0205\n",
      "Epoch [83/100], Loss: 0.0027\n",
      "Epoch [84/100], Loss: 0.0121\n",
      "Epoch [85/100], Loss: 0.0005\n",
      "Epoch [86/100], Loss: 0.0364\n",
      "Epoch [87/100], Loss: 0.0497\n",
      "Epoch [88/100], Loss: 0.0054\n",
      "Epoch [89/100], Loss: 0.0082\n",
      "Epoch [90/100], Loss: 0.0339\n",
      "Epoch [91/100], Loss: 0.0824\n",
      "Epoch [92/100], Loss: 0.0013\n",
      "Epoch [93/100], Loss: 0.0017\n",
      "Epoch [94/100], Loss: 0.0996\n",
      "Epoch [95/100], Loss: 0.3839\n",
      "Epoch [96/100], Loss: 0.0348\n",
      "Epoch [97/100], Loss: 0.0015\n",
      "Epoch [98/100], Loss: 0.0144\n",
      "Epoch [99/100], Loss: 0.0021\n",
      "Epoch [100/100], Loss: 0.0006\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(0, numEpoch):\n",
    "    for i, data in enumerate(trainLoader,0):\n",
    "        labels = Variable(data[:,-1])\n",
    "        data = Variable(data[:,0:30].float())\n",
    "        optimizer.zero_grad()\n",
    "        outputs = dnn(data)\n",
    "        loss = lossFN(outputs, labels.long())\n",
    "        loss.backward()\n",
    "        optimizer.step() \n",
    "                                        \n",
    "    print('Epoch [%d/%d], Loss: %.4f'\n",
    "        %(epoch+1, numEpoch, loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the accuracy of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the data: 96 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for data in testLoader:\n",
    "    labels = Variable(data[:,-1])\n",
    "    data = Variable(data[:,0:30].float()) \n",
    "    outputs = dnn(data)\n",
    "    _, predicted = torch.max(outputs.data, 1)  \n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels.long()).sum()\n",
    "    \n",
    "print('Accuracy of the network on the data: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
